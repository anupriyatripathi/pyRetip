{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caring-delight",
   "metadata": {},
   "source": [
    "![Retip](../images/retip_logo.png)\n",
    "# Retip: Retention Time Prediction for Metabolomics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-republican",
   "metadata": {},
   "source": [
    "### Training a Model with AutoGluon\n",
    "\n",
    "[AutoGluon](https://auto.gluon.ai) is an AutoML library designed to automate the full machine learning pipeline, including feature  preprocessing, training multiple model types, and constructing ensembles of models to improve overall accuracy.\n",
    "\n",
    "As AutoGluon performs so many tasks, the final model accuracy usually improves the longer it has to train.  We recommend 1-2 hours.\n",
    "\n",
    "We begin by importing the retip library, loading our datasets, and calculating descriptors as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grand-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import retip\n",
    "except:\n",
    "    # add the parent directory to the path to load the Retip library locally in case it isn't installed\n",
    "    import os, sys\n",
    "    sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "    \n",
    "    import retip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ahead-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = retip.Dataset(target_column='RT').load_retip_dataset(\n",
    "    training='../example_data/Plasma_positive.xlsx', training_sheet_name='lib_2',\n",
    "    validation='../example_data/Plasma_positive.xlsx', validation_sheet_name='ext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smaller-james",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors for training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 494/494 [02:02<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors for validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 358/358 [02:01<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced feature set from 1613 to 817\n"
     ]
    }
   ],
   "source": [
    "dataset.calculate_descriptors()\n",
    "dataset.preprocess_features('metabolomics')\n",
    "dataset.split_dataset(test_split=0.2, seed=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-roberts",
   "metadata": {},
   "source": [
    "### Training RT Prediction Model\n",
    "\n",
    "Similarly to XGBoost, we create a model trainer.  The main difference is that we no longer need a cross-validation parameter (AutoGluon takes care of this), and instead we need to specify the training time in minutes.  Here, we select `training_duration=30` to train for 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incident-casting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220907_132926/\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Preset 'high_quality' was not found. Valid presets: ['best_quality', 'high_quality_fast_inference_only_refit', 'good_quality_faster_inference_only_refit', 'medium_quality_faster_train', 'optimize_for_deployment', 'ignore_text']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3846840/3587562548.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoGluonTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/pyRetip/notebooks/../retip/trainers/autogluon_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_duration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mpresets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyRetip/lib/python3.7/site-packages/autogluon/core/utils/decorators.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pyRetip/lib/python3.7/site-packages/autogluon/core/utils/decorators.py\u001b[0m in \u001b[0;36m_apply_presets\u001b[0;34m(preset_dict, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mpreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreset_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpreset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Preset \\'{preset_orig}\\' was not found. Valid presets: {list(preset_dict.keys())}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Preset 'high_quality' was not found. Valid presets: ['best_quality', 'high_quality_fast_inference_only_refit', 'good_quality_faster_inference_only_refit', 'medium_quality_faster_train', 'optimize_for_deployment', 'ignore_text']"
     ]
    }
   ],
   "source": [
    "trainer = retip.AutoGluonTrainer(dataset, training_duration=60)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-burning",
   "metadata": {},
   "source": [
    "You can score this model using the internal testing data, or alternatively pass in a different `Dataset` object with precomputed descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-bruce",
   "metadata": {},
   "source": [
    "### External Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = retip.Dataset('../example_data/Plasma_positive.xlsx', sheet_name='ext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.score(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-senator",
   "metadata": {},
   "source": [
    "While we still observe the same issue where our training data is not sufficiently representative of our chemical space, the accuracy of the AutoGluon model is notably better than XGBoost, even after only 30 minutes of training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-canberra",
   "metadata": {},
   "source": [
    "### Saving/Loading Models\n",
    "\n",
    "AutoGluon automatically saves its models into a directory called `AutogluonModels`, where each model is saved into a subdirectory named according to when the model started training.  You can use the same saving and loading methods to move these save directories and reload them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('Plasma_positve_autogluon-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = retip.AutoGluonTrainer()\n",
    "trainer.load_model('AutogluonModels/ag-20210318_094225')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.score(val_data, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-explosion",
   "metadata": {},
   "source": [
    "If you use AutoGluon a lot, remember to clear out old models from the `AutogluonModels` directory!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

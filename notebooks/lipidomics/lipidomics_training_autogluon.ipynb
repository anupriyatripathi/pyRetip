{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caring-delight",
   "metadata": {},
   "source": [
    "![Retip](../../images/retip_logo.png)\n",
    "# Retip: Retention Time Prediction for Metabolomics and Lipidomics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82029ac2-54e8-4b00-92c5-7a198c18c295",
   "metadata": {},
   "source": [
    "Retip is a python tool for predicting retention times (RTs) of small molecules for high pressure liquid chromatography (HPLC) mass spectrometry. Retention time calculation can be useful in identifying unknowns and removing false positive annotations. The machine learning algorithms included in the tool are: **XGBoost**, **AutoGluon**, **AutoML** from **H2O** and **Random Forest**. This tutorial explains how to train a model with **AutoGluon**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-republican",
   "metadata": {},
   "source": [
    "## Training a Model with AutoGluon\n",
    "\n",
    "[AutoGluon](https://auto.gluon.ai) is an AutoML library designed to automate the full machine learning pipeline, including feature  preprocessing, training multiple model types, and constructing ensembles of models to improve overall accuracy.\n",
    "\n",
    "As AutoGluon performs so many tasks, the final model accuracy usually improves the longer it has to train.  When no time limit is specified, the training should take between 10 and 30 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8df30",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4fc3f4",
   "metadata": {},
   "source": [
    "Begin by importing the `pyretip` library, which provides access to the training, prediction and visualization functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "grand-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import retip\n",
    "except:\n",
    "    # add the parent directory to the path to load the Retip library locally in case it isn't installed\n",
    "    import os, sys\n",
    "    sys.path.insert(1, os.path.join(sys.path[0], '/home/npa/Documentos/pyRetip'))\n",
    "\n",
    "    import retip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7736b9c3-1d34-48e2-b74f-dc41bf5f29ab",
   "metadata": {},
   "source": [
    "The input data should be a compound retention time table in CSV or MS Excel format, containing the compound name, retention time and chemical identifier. Retip currently supports SMILES and PubChem CID as chemical identifiers.\n",
    "\n",
    "Retip will use this input file to build the model and predict retention times for other biochemical databases or an input query list of compounds. It is suggested that the file has at least 300 compounds to build a good retention time prediction model.\n",
    "\n",
    "Use the `retip.Dataset` class to load the data and create a new dataset.\n",
    "\n",
    "In this tutorial, the input data is already split into training and testing set, provided as separate CSV files. For this reason, the `split_dataset` function will not be used in this tutorial (go to the metabolomics tutorials to see how it works)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ahead-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = retip.Dataset(target_column='RT').load_retip_dataset(\n",
    "    training='lipidomics_c18_retip_training.csv',\n",
    "    testing='lipidomics_c18_retip_testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2b7553-a716-4e2f-a734-892004e92d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "       ID                         Name CompoundClass  \\\n",
      "0  860906  1_TG 14:0-13:0-14:0-d5_ISTD            TG   \n",
      "1  860907  1_TG 14:0-15:1-14:0-d5_ISTD            TG   \n",
      "\n",
      "                      InChIKey  \\\n",
      "0  AQNYNFGTMNCFBJ-GZKVWLTASA-N   \n",
      "1  DODQZOMAJARNKZ-AHFZQTAFSA-N   \n",
      "\n",
      "                                              SMILES     RT  \n",
      "0  CCCCCCCCCCCCCC(=O)OCC(COC(=O)CCCCCCCCCCCCC)OC(...  9.211  \n",
      "1  CCCC/C=C\\CCCCCCCCC(=O)OC(COC(=O)CCCCCCCCCCCCC)...  9.235  \n",
      "\n",
      "Testing\n",
      "         ID           Name CompoundClass                     InChIKey  \\\n",
      "0  53481651  CAR 10:1 [M]+           CAR  GOOOCIIXFLVRAG-UHFFFAOYSA-N   \n",
      "1  11953816  CAR 16:0 [M]+           CAR  XOMRRQXKHMYMOC-OAQYLSRUSA-N   \n",
      "\n",
      "                                           SMILES        RT  \n",
      "0       C[N+](C)(C)CC(CC(=O)[O-])OC(=O)CCCCCCCC=C  0.575773  \n",
      "1  CCCCCCCCCCCCCCCC(=O)OC(CC(=O)[O-])C[N+](C)(C)C  1.612047  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc567156",
   "metadata": {},
   "source": [
    "Next, the precalculated molecular descriptors can be computed with the [Mordred Molecular Descriptor Calculator](https://github.com/mordred-descriptor/mordred) by calling the `calculate_descriptors` function. Note that molecules that cannot be parsed will be retained the dataset, but cannot be used for model training or validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smaller-james",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors for training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:31<00:00,  6.24it/s]\n",
      "/home/npa/Documentos/pyRetip/retip/dataset.py:198: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  descs = descs.replace({False: 0, True: 1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors for testing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:10<00:00,  6.12it/s]\n",
      "/home/npa/Documentos/pyRetip/retip/dataset.py:198: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  descs = descs.replace({False: 0, True: 1})\n"
     ]
    }
   ],
   "source": [
    "dataset.calculate_descriptors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4511ec5",
   "metadata": {},
   "source": [
    "The `describe` function shows the shape of the datasets, indicating the number of rows and columns in each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "046e96e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (194, 1619)\n",
      "Testing (65, 1619)\n"
     ]
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295a1ab",
   "metadata": {},
   "source": [
    "The `preprocess_features` function performs feature reduction by removing features with missing values and to restrict feature sets to descriptors which calculate non-null values for large sets of molecules. It is important to perform this step before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49da2d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced feature set from 1613 to 1432\n"
     ]
    }
   ],
   "source": [
    "dataset.preprocess_features('lipidomics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35d995",
   "metadata": {},
   "source": [
    "#### Save the new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dade7d",
   "metadata": {},
   "source": [
    "Given that molecular descriptor calculation is a time-comsuming process, it is possible to save the current state of the dataset. Next time this retention time library is needed, simply use this export when loading this dataset instead. Note that there is no need to include a file extension, as Retip will automatically append the dataset type to the filename provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71f15fc9-fd0c-45db-9f6a-d121cf772deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training dataset to lipidomics_c18_retip_preprocessed_training.csv\n",
      "Saved testing dataset to lipidomics_c18_retip_preprocessed_testing.csv\n"
     ]
    }
   ],
   "source": [
    "dataset.save_retip_dataset('lipidomics_c18_retip_preprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0137c",
   "metadata": {},
   "source": [
    "This dataset can be loaded by running the `load_retip_dataset` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d379cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = retip.Dataset(target_column='RT').load_retip_dataset(\n",
    "#     'Plasma_positive_retip_processed_training.csv',\n",
    "#     'Plasma_positive_retip_processed_testing.csv',\n",
    "#     'Plasma_positive_retip_processed_validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2449f799",
   "metadata": {},
   "source": [
    "### Training RT Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-roberts",
   "metadata": {},
   "source": [
    "Here, the RT prediction model will be trained. First, initialize the `AutoGluonTrainer` with the dataset with computed descriptors. Set the different parameters:\n",
    "- The `training_duration` parameter indicates the maximum training time in minutes. This value defaults to `None`.\n",
    "- The `preset` paramenter indicates the balance between the training speed and the prediction quality. The options are `medium_quality`, `high_quality` and `best_quality`. This value defaults to `high_quality`.\n",
    "\n",
    "The cross-validation parameter does not need to be specified becaure AutoGluon takes care of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incident-casting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240530_113657\"\n",
      "Presets specified: ['high_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240530_113657/ds_sub_fit/sub_fit_ho.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 205 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 395 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 395s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240530_113657\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #35~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue May  7 09:00:52 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       46.48 GB / 62.71 GB (74.1%)\n",
      "Disk Space Avail:   1521.67 GB / 1831.76 GB (83.1%)\n",
      "===================================================\n",
      "Train Data Rows:    194\n",
      "Train Data Columns: 1432\n",
      "Label Column:       RT\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    47590.76 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.13 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 30 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 290): ['nAromAtom', 'nAromBond', 'nSpiro', 'nBridgehead', 'nB', 'nS', 'nF', 'nCl', 'nBr', 'nI', 'nX', 'nBondsT', 'nBondsA', 'C1SP1', 'C2SP1', 'Xch-3d', 'Xch-4d', 'Xch-3dv', 'Xch-4dv', 'NsLi', 'NssBe', 'NssssBe', 'NssBH', 'NsssB', 'NssssB', 'NdCH2', 'NtCH', 'NaaCH', 'NddC', 'NtsC', 'NaasC', 'NaaaC', 'NssNH2', 'NdNH', 'NaaNH', 'NtN', 'NsssNH', 'NdsN', 'NaaN', 'NsssN', 'NddsN', 'NaasN', 'NaaO', 'NsF', 'NsSiH3', 'NssSiH2', 'NsssSiH', 'NssssSi', 'NsPH2', 'NssPH', 'NsssP', 'NsssssP', 'NsSH', 'NdS', 'NssS', 'NaaS', 'NdssS', 'NddssS', 'NsCl', 'NsGeH3', 'NssGeH2', 'NsssGeH', 'NssssGe', 'NsAsH2', 'NssAsH', 'NsssAs', 'NsssdAs', 'NsssssAs', 'NsSeH', 'NdSe', 'NssSe', 'NaaSe', 'NdssSe', 'NddssSe', 'NsBr', 'NsSnH3', 'NssSnH2', 'NsssSnH', 'NssssSn', 'NsI', 'NsPbH3', 'NssPbH2', 'NsssPbH', 'NssssPb', 'SsLi', 'SssBe', 'SssssBe', 'SssBH', 'SsssB', 'SssssB', 'SdCH2', 'StCH', 'SaaCH', 'SddC', 'StsC', 'SaasC', 'SaaaC', 'SssNH2', 'SdNH', 'SaaNH', 'StN', 'SsssNH', 'SdsN', 'SaaN', 'SsssN', 'SddsN', 'SaasN', 'SaaO', 'SsF', 'SsSiH3', 'SssSiH2', 'SsssSiH', 'SssssSi', 'SsPH2', 'SssPH', 'SsssP', 'SsssssP', 'SsSH', 'SdS', 'SssS', 'SaaS', 'SdssS', 'SddssS', 'SsCl', 'SsGeH3', 'SssGeH2', 'SsssGeH', 'SssssGe', 'SsAsH2', 'SssAsH', 'SsssAs', 'SsssdAs', 'SsssssAs', 'SsSeH', 'SdSe', 'SssSe', 'SaaSe', 'SdssSe', 'SddssSe', 'SsBr', 'SsSnH3', 'SssSnH2', 'SsssSnH', 'SssssSn', 'SsI', 'SsPbH3', 'SssPbH2', 'SsssPbH', 'SssssPb', 'ETA_beta_ns_d', 'AETA_beta_ns_d', 'ETA_dAlpha_A', 'ETA_dPsi_B', 'PEOE_VSA4', 'PEOE_VSA5', 'SMR_VSA2', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'SlogP_VSA10', 'SlogP_VSA11', 'MID_X', 'AMID_X', 'n3Ring', 'n4Ring', 'n7Ring', 'n8Ring', 'n9Ring', 'n10Ring', 'n11Ring', 'n12Ring', 'nG12Ring', 'n3HRing', 'n4HRing', 'n5HRing', 'n7HRing', 'n8HRing', 'n9HRing', 'n10HRing', 'n11HRing', 'n12HRing', 'nG12HRing', 'naRing', 'n3aRing', 'n4aRing', 'n5aRing', 'n6aRing', 'n7aRing', 'n8aRing', 'n9aRing', 'n10aRing', 'n11aRing', 'n12aRing', 'nG12aRing', 'naHRing', 'n3aHRing', 'n4aHRing', 'n5aHRing', 'n6aHRing', 'n7aHRing', 'n8aHRing', 'n9aHRing', 'n10aHRing', 'n11aHRing', 'n12aHRing', 'nG12aHRing', 'n3ARing', 'n4ARing', 'n7ARing', 'n8ARing', 'n9ARing', 'n10ARing', 'n11ARing', 'n12ARing', 'nG12ARing', 'n3AHRing', 'n4AHRing', 'n5AHRing', 'n7AHRing', 'n8AHRing', 'n9AHRing', 'n10AHRing', 'n11AHRing', 'n12AHRing', 'nG12AHRing', 'n4FRing', 'n5FRing', 'n6FRing', 'n7FRing', 'n8FRing', 'n9FRing', 'n10FRing', 'n11FRing', 'n12FRing', 'nFHRing', 'n4FHRing', 'n5FHRing', 'n6FHRing', 'n7FHRing', 'n8FHRing', 'n9FHRing', 'n10FHRing', 'n11FHRing', 'n12FHRing', 'nG12FHRing', 'nFaRing', 'n4FaRing', 'n5FaRing', 'n6FaRing', 'n7FaRing', 'n8FaRing', 'n9FaRing', 'n10FaRing', 'n11FaRing', 'n12FaRing', 'nG12FaRing', 'nFaHRing', 'n4FaHRing', 'n5FaHRing', 'n6FaHRing', 'n7FaHRing', 'n8FaHRing', 'n9FaHRing', 'n10FaHRing', 'n11FaHRing', 'n12FaHRing', 'nG12FaHRing', 'n4FARing', 'n5FARing', 'n6FARing', 'n7FARing', 'n8FARing', 'n9FARing', 'n10FARing', 'n11FARing', 'n12FARing', 'nFAHRing', 'n4FAHRing', 'n5FAHRing', 'n6FAHRing', 'n7FAHRing', 'n8FAHRing', 'n9FAHRing', 'n10FAHRing', 'n11FAHRing', 'n12FAHRing', 'nG12FAHRing', 'SRW03']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 36): ['LogEE_DzZ', 'LogEE_Dzm', 'LogEE_Dzv', 'LogEE_Dzse', 'LogEE_Dzpe', 'LogEE_Dzare', 'LogEE_Dzp', 'LogEE_Dzi', 'nBondsM', 'nBondsKS', 'nBondsKD', 'C3SP3', 'C4SP3', 'FCSP3', 'Xch-5d', 'Xch-5dv', 'LogEE_D', 'NssssC', 'NdsssP', 'SMR_VSA3', 'SlogP_VSA6', 'n5Ring', 'n6HRing', 'nARing', 'n5ARing', 'n6ARing', 'nAHRing', 'n6AHRing', 'nFRing', 'nG12FRing', 'nFARing', 'nG12FARing', 'MWC01', 'SRW05', 'SRW07', 'SRW09']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 18 | ['LogEE_DzZ', 'LogEE_Dzm', 'LogEE_Dzv', 'LogEE_Dzse', 'LogEE_Dzpe', ...]\n",
      "\t\t('int', [])   : 18 | ['nBondsM', 'nBondsKS', 'nBondsKD', 'C3SP3', 'C4SP3', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1052 | ['ABC', 'ABCGG', 'SpAbs_A', 'SpMax_A', 'SpDiam_A', ...]\n",
      "\t\t('int', [])   :   54 | ['nAcid', 'nBase', 'nAtom', 'nHeavyAtom', 'nHetero', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 1051 | ['ABC', 'ABCGG', 'SpAbs_A', 'SpMax_A', 'SpDiam_A', ...]\n",
      "\t\t('int', [])       :   44 | ['nAcid', 'nAtom', 'nHeavyAtom', 'nHetero', 'nH', ...]\n",
      "\t\t('int', ['bool']) :   11 | ['nBase', 'nP', 'C3SP2', 'NsNH3', 'NsNH2', ...]\n",
      "\t1.3s = Fit runtime\n",
      "\t1106 features in original data used to generate 1106 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.63 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.38s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 262.35s of the 393.61s of remaining time.\n",
      "\t-1.4147\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 262.09s of the 393.35s of remaining time.\n",
      "\t-1.1686\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 261.86s of the 393.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.44%)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=54250, ip=192.168.1.177)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 3433, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2462, in construct\n",
      "    self._lazy_init(data=self.data, label=self.label, reference=None,\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2022, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 825, in _data_from_pandas\n",
      "    _pandas_to_numpy(data, target_dtype=target_dtype),\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 771, in _pandas_to_numpy\n",
      "    _check_for_bad_pandas_dtypes(data.dtypes)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 763, in _check_for_bad_pandas_dtypes\n",
      "    raise ValueError('pandas dtypes must be int, float or bool.\\n'\n",
      "ValueError: pandas dtypes must be int, float or bool.\n",
      "Fields with bad pandas dtypes: MDEC-12: float128, MDEC-13: float128, MDEC-22: float128, MDEC-23: float128\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=54250, ip=192.168.1.177)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 3433, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2462, in construct\n",
      "    self._lazy_init(data=self.data, label=self.label, reference=None,\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2022, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 825, in _data_from_pandas\n",
      "    _pandas_to_numpy(data, target_dtype=target_dtype),\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 771, in _pandas_to_numpy\n",
      "    _check_for_bad_pandas_dtypes(data.dtypes)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 763, in _check_for_bad_pandas_dtypes\n",
      "    raise ValueError('pandas dtypes must be int, float or bool.\\n'\n",
      "ValueError: pandas dtypes must be int, float or bool.\n",
      "Fields with bad pandas dtypes: MDEC-12: float128, MDEC-13: float128, MDEC-22: float128, MDEC-23: float128\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 259.47s of the 390.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.44%)\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=54727, ip=192.168.1.177)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 3433, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2462, in construct\n",
      "    self._lazy_init(data=self.data, label=self.label, reference=None,\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2022, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 825, in _data_from_pandas\n",
      "    _pandas_to_numpy(data, target_dtype=target_dtype),\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 771, in _pandas_to_numpy\n",
      "    _check_for_bad_pandas_dtypes(data.dtypes)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 763, in _check_for_bad_pandas_dtypes\n",
      "    raise ValueError('pandas dtypes must be int, float or bool.\\n'\n",
      "ValueError: pandas dtypes must be int, float or bool.\n",
      "Fields with bad pandas dtypes: MDEC-12: float128, MDEC-13: float128, MDEC-22: float128, MDEC-23: float128\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=54727, ip=192.168.1.177)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 3433, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2462, in construct\n",
      "    self._lazy_init(data=self.data, label=self.label, reference=None,\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2022, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 825, in _data_from_pandas\n",
      "    _pandas_to_numpy(data, target_dtype=target_dtype),\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 771, in _pandas_to_numpy\n",
      "    _check_for_bad_pandas_dtypes(data.dtypes)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 763, in _check_for_bad_pandas_dtypes\n",
      "    raise ValueError('pandas dtypes must be int, float or bool.\\n'\n",
      "ValueError: pandas dtypes must be int, float or bool.\n",
      "Fields with bad pandas dtypes: MDEC-12: float128, MDEC-13: float128, MDEC-22: float128, MDEC-23: float128\n",
      "2024-05-30 13:40:29,088\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:40:29,093\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:40:29,094\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:40:29,095\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:40:29,096\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 257.18s of the 388.44s of remaining time.\n",
      "2024-05-30 13:40:29,100\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:40:29,101\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.2798\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.91s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 255.05s of the 386.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.88%)\n",
      "2024-05-30 13:40:34,027\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:40:34,028\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:40:34,029\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:40:34,029\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:40:34,030\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:40:34,030\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:40:34,031\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.321\t = Validation score   (-root_mean_squared_error)\n",
      "\t204.04s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 49.32s of the 180.58s of remaining time.\n",
      "\t-0.2846\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.76s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 47.35s of the 178.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=56228, ip=192.168.1.177)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 407, in _ray_fit\n",
      "    fold_model, pred_proba = _ray_predict_oof(fold_model, X_val_fold, y_val_fold, time_train_end_fold, resources[\"num_cpus\"], save_bag_folds)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 417, in _ray_predict_oof\n",
      "    pred_proba = fold_model.predict_proba(X_val_fold, num_cpus=num_cpus)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 950, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 485, in _predict_proba\n",
      "    preds, _ = self.model.get_preds(dl=test_dl)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 308, in get_preds\n",
      "    self._do_epoch_validate(dl=dl)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 244, in _do_epoch_validate\n",
      "    with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 205, in all_batches\n",
      "    for o in enumerate(self.dl): self.one_batch(*o)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/data/load.py\", line 131, in __iter__\n",
      "    yield self.after_batch(b)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 208, in __call__\n",
      "    def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 158, in compose_tfms\n",
      "    x = f(x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 121, in __call__\n",
      "    def __call__(self, x, **kwargs): return self._call1(x, '__call__', **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 124, in _call1\n",
      "    if not _is_tuple(x): return getattr(super(), name)(x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 81, in __call__\n",
      "    def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 91, in _call\n",
      "    return self._do_call(getattr(self, fn), x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 97, in _do_call\n",
      "    return retain_type(f(x, **kwargs), x, ret)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/dispatch.py\", line 120, in __call__\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/tabular/core.py\", line 327, in encodes\n",
      "    else: res = (tensor(to.cats).long(),tensor(to.conts).float())\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/torch_core.py\", line 152, in tensor\n",
      "    else as_tensor(x.values, **kwargs) if isinstance(x, (pd.Series, pd.DataFrame))\n",
      "TypeError: can't convert np.ndarray of type numpy.longdouble. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=56228, ip=192.168.1.177)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 407, in _ray_fit\n",
      "    fold_model, pred_proba = _ray_predict_oof(fold_model, X_val_fold, y_val_fold, time_train_end_fold, resources[\"num_cpus\"], save_bag_folds)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 417, in _ray_predict_oof\n",
      "    pred_proba = fold_model.predict_proba(X_val_fold, num_cpus=num_cpus)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 950, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 485, in _predict_proba\n",
      "    preds, _ = self.model.get_preds(dl=test_dl)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 308, in get_preds\n",
      "    self._do_epoch_validate(dl=dl)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 244, in _do_epoch_validate\n",
      "    with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 205, in all_batches\n",
      "    for o in enumerate(self.dl): self.one_batch(*o)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/data/load.py\", line 131, in __iter__\n",
      "    yield self.after_batch(b)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 208, in __call__\n",
      "    def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 158, in compose_tfms\n",
      "    x = f(x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 121, in __call__\n",
      "    def __call__(self, x, **kwargs): return self._call1(x, '__call__', **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 124, in _call1\n",
      "    if not _is_tuple(x): return getattr(super(), name)(x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 81, in __call__\n",
      "    def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 91, in _call\n",
      "    return self._do_call(getattr(self, fn), x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 97, in _do_call\n",
      "    return retain_type(f(x, **kwargs), x, ret)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/dispatch.py\", line 120, in __call__\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/tabular/core.py\", line 327, in encodes\n",
      "    else: res = (tensor(to.cats).long(),tensor(to.conts).float())\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/torch_core.py\", line 152, in tensor\n",
      "    else as_tensor(x.values, **kwargs) if isinstance(x, (pd.Series, pd.DataFrame))\n",
      "TypeError: can't convert np.ndarray of type numpy.longdouble. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 34.07s of the 165.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.82%)\n",
      "2024-05-30 13:44:17,243\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:44:17,244\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:44:17,244\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:44:17,245\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:44:17,246\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:44:17,246\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:44:17,247\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3402\t = Validation score   (-root_mean_squared_error)\n",
      "\t28.08s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 4.37s of the 135.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t-0.2314\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.19s\t = Training   runtime\n",
      "\t1.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 127.22s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.545, 'RandomForestMSE_BAG_L1': 0.182, 'CatBoost_BAG_L1': 0.136, 'XGBoost_BAG_L1': 0.091, 'ExtraTreesMSE_BAG_L1': 0.045}\n",
      "\t-0.201\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 127.18s of the 127.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.41%)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=57945, ip=192.168.1.177)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 3433, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2462, in construct\n",
      "    self._lazy_init(data=self.data, label=self.label, reference=None,\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2022, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 825, in _data_from_pandas\n",
      "    _pandas_to_numpy(data, target_dtype=target_dtype),\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 771, in _pandas_to_numpy\n",
      "    _check_for_bad_pandas_dtypes(data.dtypes)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 763, in _check_for_bad_pandas_dtypes\n",
      "    raise ValueError('pandas dtypes must be int, float or bool.\\n'\n",
      "ValueError: pandas dtypes must be int, float or bool.\n",
      "Fields with bad pandas dtypes: MDEC-12: float128, MDEC-13: float128, MDEC-22: float128, MDEC-23: float128\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=57945, ip=192.168.1.177)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 3433, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2462, in construct\n",
      "    self._lazy_init(data=self.data, label=self.label, reference=None,\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2022, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 825, in _data_from_pandas\n",
      "    _pandas_to_numpy(data, target_dtype=target_dtype),\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 771, in _pandas_to_numpy\n",
      "    _check_for_bad_pandas_dtypes(data.dtypes)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 763, in _check_for_bad_pandas_dtypes\n",
      "    raise ValueError('pandas dtypes must be int, float or bool.\\n'\n",
      "ValueError: pandas dtypes must be int, float or bool.\n",
      "Fields with bad pandas dtypes: MDEC-12: float128, MDEC-13: float128, MDEC-22: float128, MDEC-23: float128\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 124.97s of the 124.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.40%)\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=58415, ip=192.168.1.177)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 3433, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2462, in construct\n",
      "    self._lazy_init(data=self.data, label=self.label, reference=None,\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2022, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 825, in _data_from_pandas\n",
      "    _pandas_to_numpy(data, target_dtype=target_dtype),\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 771, in _pandas_to_numpy\n",
      "    _check_for_bad_pandas_dtypes(data.dtypes)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 763, in _check_for_bad_pandas_dtypes\n",
      "    raise ValueError('pandas dtypes must be int, float or bool.\\n'\n",
      "ValueError: pandas dtypes must be int, float or bool.\n",
      "Fields with bad pandas dtypes: MDEC-12: float128, MDEC-13: float128, MDEC-22: float128, MDEC-23: float128\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=58415, ip=192.168.1.177)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/engine.py\", line 255, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 3433, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2462, in construct\n",
      "    self._lazy_init(data=self.data, label=self.label, reference=None,\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 2022, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 825, in _data_from_pandas\n",
      "    _pandas_to_numpy(data, target_dtype=target_dtype),\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 771, in _pandas_to_numpy\n",
      "    _check_for_bad_pandas_dtypes(data.dtypes)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/lightgbm/basic.py\", line 763, in _check_for_bad_pandas_dtypes\n",
      "    raise ValueError('pandas dtypes must be int, float or bool.\\n'\n",
      "ValueError: pandas dtypes must be int, float or bool.\n",
      "Fields with bad pandas dtypes: MDEC-12: float128, MDEC-13: float128, MDEC-22: float128, MDEC-23: float128\n",
      "2024-05-30 13:44:54,606\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:44:54,607\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:44:54,607\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:44:54,608\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:44:54,608\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:44:54,609\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:44:54,609\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 122.95s of the 122.91s of remaining time.\n",
      "\t-0.2585\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.04s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 120.69s of the 120.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.80%)\n",
      "2024-05-30 13:45:00,260\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:45:00,261\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:45:00,261\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:45:00,262\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:45:00,263\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:45:00,263\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:45:00,264\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.3062\t = Validation score   (-root_mean_squared_error)\n",
      "\t96.58s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 22.48s of the 22.44s of remaining time.\n",
      "\t-0.2577\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.62s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 20.63s of the 20.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=59664, ip=192.168.1.177)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 407, in _ray_fit\n",
      "    fold_model, pred_proba = _ray_predict_oof(fold_model, X_val_fold, y_val_fold, time_train_end_fold, resources[\"num_cpus\"], save_bag_folds)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 417, in _ray_predict_oof\n",
      "    pred_proba = fold_model.predict_proba(X_val_fold, num_cpus=num_cpus)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 950, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 485, in _predict_proba\n",
      "    preds, _ = self.model.get_preds(dl=test_dl)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 308, in get_preds\n",
      "    self._do_epoch_validate(dl=dl)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 244, in _do_epoch_validate\n",
      "    with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 205, in all_batches\n",
      "    for o in enumerate(self.dl): self.one_batch(*o)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/data/load.py\", line 131, in __iter__\n",
      "    yield self.after_batch(b)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 208, in __call__\n",
      "    def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 158, in compose_tfms\n",
      "    x = f(x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 121, in __call__\n",
      "    def __call__(self, x, **kwargs): return self._call1(x, '__call__', **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 124, in _call1\n",
      "    if not _is_tuple(x): return getattr(super(), name)(x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 81, in __call__\n",
      "    def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 91, in _call\n",
      "    return self._do_call(getattr(self, fn), x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 97, in _do_call\n",
      "    return retain_type(f(x, **kwargs), x, ret)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/dispatch.py\", line 120, in __call__\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/tabular/core.py\", line 327, in encodes\n",
      "    else: res = (tensor(to.cats).long(),tensor(to.conts).float())\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/torch_core.py\", line 152, in tensor\n",
      "    else as_tensor(x.values, **kwargs) if isinstance(x, (pd.Series, pd.DataFrame))\n",
      "TypeError: can't convert np.ndarray of type numpy.longdouble. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=59664, ip=192.168.1.177)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 407, in _ray_fit\n",
      "    fold_model, pred_proba = _ray_predict_oof(fold_model, X_val_fold, y_val_fold, time_train_end_fold, resources[\"num_cpus\"], save_bag_folds)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 417, in _ray_predict_oof\n",
      "    pred_proba = fold_model.predict_proba(X_val_fold, num_cpus=num_cpus)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 950, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 485, in _predict_proba\n",
      "    preds, _ = self.model.get_preds(dl=test_dl)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 308, in get_preds\n",
      "    self._do_epoch_validate(dl=dl)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 244, in _do_epoch_validate\n",
      "    with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/learner.py\", line 205, in all_batches\n",
      "    for o in enumerate(self.dl): self.one_batch(*o)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/data/load.py\", line 131, in __iter__\n",
      "    yield self.after_batch(b)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 208, in __call__\n",
      "    def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 158, in compose_tfms\n",
      "    x = f(x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 121, in __call__\n",
      "    def __call__(self, x, **kwargs): return self._call1(x, '__call__', **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 124, in _call1\n",
      "    if not _is_tuple(x): return getattr(super(), name)(x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 81, in __call__\n",
      "    def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 91, in _call\n",
      "    return self._do_call(getattr(self, fn), x, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/transform.py\", line 97, in _do_call\n",
      "    return retain_type(f(x, **kwargs), x, ret)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastcore/dispatch.py\", line 120, in __call__\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/tabular/core.py\", line 327, in encodes\n",
      "    else: res = (tensor(to.cats).long(),tensor(to.conts).float())\n",
      "  File \"/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/fastai/torch_core.py\", line 152, in tensor\n",
      "    else as_tensor(x.values, **kwargs) if isinstance(x, (pd.Series, pd.DataFrame))\n",
      "TypeError: can't convert np.ndarray of type numpy.longdouble. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 7.37s of the 7.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.82%)\n",
      "2024-05-30 13:46:55,340\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:46:55,341\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:46:55,341\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:46:55,342\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:46:55,342\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:46:55,342\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-05-30 13:46:55,343\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-0.5637\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.47s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -3.13s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.522, 'RandomForestMSE_BAG_L1': 0.13, 'CatBoost_BAG_L2': 0.13, 'XGBoost_BAG_L1': 0.087, 'RandomForestMSE_BAG_L2': 0.087, 'CatBoost_BAG_L1': 0.043}\n",
      "\t-0.1994\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 398.18s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.91s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t24.91s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.76s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t2.21s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t1.04s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.545, 'RandomForestMSE_BAG_L1': 0.182, 'CatBoost_BAG_L1': 0.136, 'XGBoost_BAG_L1': 0.091, 'ExtraTreesMSE_BAG_L1': 0.045}\n",
      "\t0.01s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t2.04s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t14.06s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t1.62s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.83s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch_BAG_L1': 0.522, 'RandomForestMSE_BAG_L1': 0.13, 'CatBoost_BAG_L2': 0.13, 'XGBoost_BAG_L1': 0.087, 'RandomForestMSE_BAG_L2': 0.087, 'CatBoost_BAG_L1': 0.043}\n",
      "\t0.01s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 44.94s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240530_113657\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 0:10:48.632222 with best RMSE 0.199\n"
     ]
    }
   ],
   "source": [
    "trainer = retip.AutoGluonTrainer(dataset, training_duration=10)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c00c01",
   "metadata": {},
   "source": [
    "### Testing the RT Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-burning",
   "metadata": {},
   "source": [
    "The model can be scored using the internal testing data of the `Dataset` object, or alternatively pass a dataframe with precomputed descriptors. In that case, the `target_column` needs to be specified. Set the `plot` parameter to `True` to visualize how well the model works. Moreover, it is possible to save the plot indicating the `plot_filename`.You can score this model using the internal testing data, or alternatively pass in a different `Dataset` object with precomputed descriptors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baa7f68",
   "metadata": {},
   "source": [
    "#### Internal testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "advance-pledge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"bd8b9f5e-444a-4399-8403-a7e72581c791\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"bd8b9f5e-444a-4399-8403-a7e72581c791\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"bd8b9f5e-444a-4399-8403-a7e72581c791\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"f5bf59bd-f5cf-46fa-9d67-cc46d72e1b29\" data-root-id=\"p1001\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"65cf50ca-970d-4119-a1ae-8404b5a29317\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1001\",\"attributes\":{\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1002\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1003\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1010\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1011\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1008\"},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1039\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1033\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1034\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1035\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"pkR/Wbts4j/2Akle8cr5P7XEWBP8JANAQdk2urqb9T8C8JHF5FwkQBzWaPpr0CNAbiafUczdIEBDZpRSw80ZQODzMKUP4hlAOJ3H1YZuF0Abh+syq3wZQBzmkWAmFx9A7DrajGFKG0DVVES9SM/3P/Da5ylZK/o/kA65YEMc8D8rc5Uc5xIDQDJjXR5jxfw/j0OzoVEY8z/5hzevDcoUQA6Li4Jk/hFASKOViqwsE0DXovv152cWQJplueY6qxdAzj+r4HgXGUBfEpw3pBYRQO6X4rnd/BVAd4KLgtE8FEBm+kupUHERQCYr8UYHUhRAmmW55jqrF0Dg0YL0bb8XQBq3EmZMhBpAWlZVwCFGF0AdMi/RagAUQJPyn9096hFAcfxsvvPWFkDnW8Yd1LcRQDdI1zjamhlA932TAftrHED0BJQWxm0bQGWu1P+u0RxAMkNNbsAdH0CTx6hyp/odQJxhAGd9XSBATTJRCA0uJEC2ifgmBD8jQDbj3kNcYyNANYSdQcelJkD1tTtfRJcjQP22SFZVoCVAJUOnSggUJECQPMbLiSgnQHjEtn9E+SRAfFW6/eo+JEB74lppKdUnQB2K6d+BgSdAs83wE8UdJkCmFLPfjIQiQOcuTwiZ3ydA1YKs4QEjJkDYTWNaHxkoQOcuTwiZ3ydADv3gagf6I0Dip/WnIoEmQA==\"},\"shape\":[65],\"dtype\":\"float64\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AlUjP4Ex5z/oCCJAONasP0/uH0FEiR5B+4QFQc9AxkCazslAl3m2QNHXxEAsePZAZ9TwQEpBxT/YhMU//rqRP4i1AUB4+c4/CXCcP1xiqEBaCpVAfXybQFiaskCt9bxACUnGQGrHjEAdmrVA2YClQE7Ek0B69qFAroq8QIFvu0DZR9NA/QWsQJ/4nUAxKI9AYKK+QNEFkkBHXddAzpjrQFgP2kDHyeVAgrX/QLJm70C44QFB1SchQQE/GEHjBhlBYEg0QXFHHEGP9ytBKyQhQXXCNkHQ7idB138iQSh3OkEXdDhBnLcvQd4ZFkFPuDpBwX0vQYFpPEFlijpBzN4hQfmLNEE=\"},\"shape\":[65],\"dtype\":\"float32\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1040\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1041\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1036\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":3},\"line_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1037\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":3},\"line_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1038\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":3},\"line_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1009\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1022\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1023\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1024\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1025\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1030\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1031\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1032\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1017\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1018\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1019\"},\"axis_label\":\"Predicted RT\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1020\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1012\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1013\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1014\"},\"axis_label\":\"Library RT\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1015\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1016\",\"attributes\":{\"axis\":{\"id\":\"p1012\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1021\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1017\"}}},{\"type\":\"object\",\"name\":\"Slope\",\"id\":\"p1042\",\"attributes\":{\"gradient\":1,\"y_intercept\":0,\"line_alpha\":0.5}},{\"type\":\"object\",\"name\":\"Slope\",\"id\":\"p1043\",\"attributes\":{\"gradient\":0.984535233825636,\"y_intercept\":0.09320105561243762,\"line_color\":\"blue\"}}]}}]}};\n  const render_items = [{\"docid\":\"65cf50ca-970d-4119-a1ae-8404b5a29317\",\"roots\":{\"p1001\":\"f5bf59bd-f5cf-46fa-9d67-cc46d72e1b29\"},\"root_ids\":[\"p1001\"]}];\n  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1001"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/npa/miniconda3/envs/pyretip/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 0.1794124258296555,\n",
       " 'mean_squared_error': 0.03218881854208163,\n",
       " 'mean_absolute_error': 0.13143539799879345,\n",
       " 'median_absolute_error': 0.10017209273193295,\n",
       " 'explained_variance_score': 0.9970045146022016,\n",
       " 'mean_absolute_percentage_error': 0.027884256673622616,\n",
       " 'absolute_median_relative_error': 0.013533038516304547,\n",
       " 'r2_score': 0.996985904864986,\n",
       " 'pearson_correlation': 0.9985812263633,\n",
       " '90_percent_confidence_interval': 0.24331293331573275,\n",
       " '95_percent_confidence_interval': 0.30829230473254426}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.score(plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3467b47e",
   "metadata": {},
   "source": [
    "### RT Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be4cfc",
   "metadata": {},
   "source": [
    "The trained model can be used to predict retention times for a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ae8ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.638016\n",
       "1     1.806198\n",
       "2     2.531794\n",
       "3     1.350287\n",
       "4     9.995681\n",
       "5     9.908512\n",
       "6     8.344966\n",
       "7     6.195411\n",
       "8     6.306470\n",
       "9     5.702343\n",
       "10    6.151345\n",
       "11    7.702169\n",
       "12    7.525928\n",
       "13    1.541055\n",
       "14    1.543117\n",
       "15    1.138519\n",
       "16    2.026705\n",
       "17    1.616988\n",
       "18    1.222169\n",
       "19    5.262007\n",
       "20    4.657514\n",
       "21    4.858946\n",
       "22    5.581341\n",
       "23    5.904990\n",
       "24    6.196415\n",
       "Name: RT, dtype: float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = trainer.predict(dataset.get_testing_data())\n",
    "y_pred[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6b8d4",
   "metadata": {},
   "source": [
    "These predicted values can be annotated to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "343b12c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated = trainer.annotate(dataset.get_testing_data(include_metadata=True), prediction_column='RTP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b78b09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>CompoundClass</th>\n",
       "      <th>InChIKey</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>RTP</th>\n",
       "      <th>RT</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABCGG</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb1</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53481651</td>\n",
       "      <td>CAR 10:1 [M]+</td>\n",
       "      <td>CAR</td>\n",
       "      <td>GOOOCIIXFLVRAG-UHFFFAOYSA-N</td>\n",
       "      <td>C[N+](C)(C)CC(CC(=O)[O-])OC(=O)CCCCCCCC=C</td>\n",
       "      <td>0.638016</td>\n",
       "      <td>0.575773</td>\n",
       "      <td>15.654168</td>\n",
       "      <td>13.818090</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.247925</td>\n",
       "      <td>54.121383</td>\n",
       "      <td>313.225308</td>\n",
       "      <td>5.909911</td>\n",
       "      <td>1358</td>\n",
       "      <td>22</td>\n",
       "      <td>94.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>10.145833</td>\n",
       "      <td>5.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11953816</td>\n",
       "      <td>CAR 16:0 [M]+</td>\n",
       "      <td>CAR</td>\n",
       "      <td>XOMRRQXKHMYMOC-OAQYLSRUSA-N</td>\n",
       "      <td>CCCCCCCCCCCCCCCC(=O)OC(CC(=O)[O-])C[N+](C)(C)C</td>\n",
       "      <td>1.806198</td>\n",
       "      <td>1.612047</td>\n",
       "      <td>19.896808</td>\n",
       "      <td>15.891835</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.383873</td>\n",
       "      <td>61.075850</td>\n",
       "      <td>399.334859</td>\n",
       "      <td>5.470341</td>\n",
       "      <td>3031</td>\n",
       "      <td>28</td>\n",
       "      <td>118.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>11.645833</td>\n",
       "      <td>6.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6426855</td>\n",
       "      <td>CAR 18:0 [M]+</td>\n",
       "      <td>CAR</td>\n",
       "      <td>FNPHNLNTJNMAEE-UHFFFAOYSA-N</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCC(=O)OC(CC(=O)[O-])C[N+](C)(C)C</td>\n",
       "      <td>2.531794</td>\n",
       "      <td>2.393059</td>\n",
       "      <td>21.311022</td>\n",
       "      <td>16.518372</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.425371</td>\n",
       "      <td>63.356146</td>\n",
       "      <td>427.366159</td>\n",
       "      <td>5.409698</td>\n",
       "      <td>3802</td>\n",
       "      <td>30</td>\n",
       "      <td>126.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>12.145833</td>\n",
       "      <td>7.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6450015</td>\n",
       "      <td>CAR 18:2 [M]+</td>\n",
       "      <td>CAR</td>\n",
       "      <td>MJLXQSQYKZWZCB-DQFWFXSYSA-N</td>\n",
       "      <td>CCCCCC=CCC=CCCCCCCCC(=O)OC(CC(=O)[O-])C[N+](C)...</td>\n",
       "      <td>1.350287</td>\n",
       "      <td>1.350520</td>\n",
       "      <td>21.311022</td>\n",
       "      <td>16.518372</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.425371</td>\n",
       "      <td>63.356146</td>\n",
       "      <td>423.334859</td>\n",
       "      <td>5.644465</td>\n",
       "      <td>3802</td>\n",
       "      <td>30</td>\n",
       "      <td>126.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>12.145833</td>\n",
       "      <td>7.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6436907</td>\n",
       "      <td>CE 18:3 [2M+Na]+</td>\n",
       "      <td>CE</td>\n",
       "      <td>FYMCIBHUFSIWCE-WVXFKAQASA-N</td>\n",
       "      <td>CCC=CCC=CCC=CCCCCCCCC(=O)OC1CCC2(C3CCC4(C(C3CC...</td>\n",
       "      <td>9.995681</td>\n",
       "      <td>10.181433</td>\n",
       "      <td>35.742977</td>\n",
       "      <td>23.096223</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.791605</td>\n",
       "      <td>99.139349</td>\n",
       "      <td>646.568882</td>\n",
       "      <td>5.343544</td>\n",
       "      <td>11882</td>\n",
       "      <td>75</td>\n",
       "      <td>236.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>15.375000</td>\n",
       "      <td>10.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1439 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID              Name CompoundClass                     InChIKey  \\\n",
       "0  53481651     CAR 10:1 [M]+           CAR  GOOOCIIXFLVRAG-UHFFFAOYSA-N   \n",
       "1  11953816     CAR 16:0 [M]+           CAR  XOMRRQXKHMYMOC-OAQYLSRUSA-N   \n",
       "2   6426855     CAR 18:0 [M]+           CAR  FNPHNLNTJNMAEE-UHFFFAOYSA-N   \n",
       "3   6450015     CAR 18:2 [M]+           CAR  MJLXQSQYKZWZCB-DQFWFXSYSA-N   \n",
       "4   6436907  CE 18:3 [2M+Na]+            CE  FYMCIBHUFSIWCE-WVXFKAQASA-N   \n",
       "\n",
       "                                              SMILES       RTP         RT  \\\n",
       "0          C[N+](C)(C)CC(CC(=O)[O-])OC(=O)CCCCCCCC=C  0.638016   0.575773   \n",
       "1     CCCCCCCCCCCCCCCC(=O)OC(CC(=O)[O-])C[N+](C)(C)C  1.806198   1.612047   \n",
       "2   CCCCCCCCCCCCCCCCCC(=O)OC(CC(=O)[O-])C[N+](C)(C)C  2.531794   2.393059   \n",
       "3  CCCCCC=CCC=CCCCCCCCC(=O)OC(CC(=O)[O-])C[N+](C)...  1.350287   1.350520   \n",
       "4  CCC=CCC=CCC=CCCCCCCCC(=O)OC1CCC2(C3CCC4(C(C3CC...  9.995681  10.181433   \n",
       "\n",
       "         ABC      ABCGG  nAcid  ...      SRW10     TSRW10          MW  \\\n",
       "0  15.654168  13.818090      1  ...   9.247925  54.121383  313.225308   \n",
       "1  19.896808  15.891835      1  ...   9.383873  61.075850  399.334859   \n",
       "2  21.311022  16.518372      1  ...   9.425371  63.356146  427.366159   \n",
       "3  21.311022  16.518372      1  ...   9.425371  63.356146  423.334859   \n",
       "4  35.742977  23.096223      0  ...  10.791605  99.139349  646.568882   \n",
       "\n",
       "        AMW  WPath  WPol  Zagreb1  Zagreb2   mZagreb1   mZagreb2  \n",
       "0  5.909911   1358    22     94.0     95.0  10.145833   5.125000  \n",
       "1  5.470341   3031    28    118.0    119.0  11.645833   6.625000  \n",
       "2  5.409698   3802    30    126.0    127.0  12.145833   7.125000  \n",
       "3  5.644465   3802    30    126.0    127.0  12.145833   7.125000  \n",
       "4  5.343544  11882    75    236.0    275.0  15.375000  10.666667  \n",
       "\n",
       "[5 rows x 1439 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786d5835",
   "metadata": {},
   "source": [
    "Now the dataset includes a new column `RTP` containing the predicted retention time. The `RTP` values of molecules that could not be loaded or descriptors could not be calculated will be empty or null."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2508c7",
   "metadata": {},
   "source": [
    "### Saving/Loading Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077e9e3",
   "metadata": {},
   "source": [
    "AutoGluon automatically saves its models into a directory called `AutogluonModels`, where each model is saved into a subdirectory named according to when the model started training.  You can use the same saving and loading methods to move these save directories and reload them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad41c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved AutoGluon model to lipidomics_c18_autogluon-model\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('lipidomics_c18_autogluon-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8dbd74",
   "metadata": {},
   "source": [
    "This exported model can then be reloaded and used to score datasets and predict new retention times. However, unless a dataset is first passed to the trainer, it cannot be retrained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a29855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded lipidomics_c18_autogluon-model\n"
     ]
    }
   ],
   "source": [
    "trainer = retip.AutoGluonTrainer()\n",
    "trainer.load_model('lipidomics_c18_autogluon-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-explosion",
   "metadata": {},
   "source": [
    "If you use AutoGluon a lot, remember to clear out old models from the `AutogluonModels` directory!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
